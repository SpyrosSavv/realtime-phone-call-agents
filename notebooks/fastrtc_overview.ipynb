{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f326ad08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a573c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from realtime_phone_agents.config import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d51ed01",
   "metadata": {},
   "source": [
    "### Example 1: Echo Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d0fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from fastrtc import Stream, StreamHandler\n",
    "\n",
    "class EchoHandler(StreamHandler): # StreamHandler giving you the full control over how the audio comes in, how it is processed and how it is sent out\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.queue = Queue()\n",
    "\n",
    "    def receive(self, frame: tuple[int, np.ndarray]) -> None:\n",
    "        self.queue.put(frame) # this is going to receive the audio frames\n",
    "\n",
    "    def emit(self) -> None:\n",
    "        return self.queue.get() # return the audio frame\n",
    "\n",
    "    def copy(self) -> StreamHandler:\n",
    "        return EchoHandler()\n",
    "    \n",
    "    def shutdown(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def start_up(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cda51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = Stream(handler=EchoHandler(), modality=\"audio\", mode=\"send-receive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5756ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.ui.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251d3be",
   "metadata": {},
   "source": [
    "### Example 2: Async Echo Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import numpy as np\n",
    "from fastrtc import AsyncStreamHandler, Stream, wait_for_item\n",
    "\n",
    "\n",
    "class AsyncEchoHandler(AsyncStreamHandler):\n",
    "    \"\"\"Simple Async Echo Handler\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(input_sample_rate=24000)\n",
    "        self.queue = asyncio.Queue()\n",
    "\n",
    "    async def receive(self, frame: tuple[int, np.ndarray]) -> None:\n",
    "        await self.queue.put(frame)\n",
    "\n",
    "    async def emit(self) -> None:\n",
    "        return await wait_for_item(self.queue)\n",
    "\n",
    "    def copy(self):\n",
    "        return AsyncEchoHandler()\n",
    "\n",
    "    async def shutdown(self):\n",
    "        pass\n",
    "\n",
    "    async def start_up(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a78344",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = Stream(handler=AsyncEchoHandler(), modality=\"audio\", mode=\"send-receive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15c385",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.ui.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88205db4",
   "metadata": {},
   "source": [
    "### Example 3: ReplyOnPause Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4cb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fastrtc import ReplyOnPause, Stream\n",
    "\n",
    "def echo(audio: tuple[int, np.ndarray]):\n",
    "    yield audio\n",
    "\n",
    "stream = Stream(\n",
    "    handler=ReplyOnPause(echo),\n",
    "    modality=\"audio\",\n",
    "    mode=\"send-receive\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa204ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.ui.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e3cf1d",
   "metadata": {},
   "source": [
    "### Example 4: Adding TTS and STT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd945670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e89bf4a47014f4981643f2ad76a831a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/merged/base/float/encoder_model.onn(…):   0%|          | 0.00/80.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983962392c2645eb80f0fdf65cd93cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/merged/base/float/decoder_model_mer(…):   0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m:\t  Warming up STT model.\n",
      "\u001b[32mINFO\u001b[0m:\t  STT model warmed up.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c558bdd634c416b9c8888c5b5ce2311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "kokoro-v1.0.onnx:   0%|          | 0.00/326M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acccdd9318f4fc5b11f2a298ab155a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "voices-v1.0.bin:   0%|          | 0.00/28.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m:\t  Warming up VAD model.\n",
      "\u001b[32mINFO\u001b[0m:\t  VAD model warmed up.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from fastrtc import ReplyOnPause, Stream, get_stt_model, get_tts_model\n",
    "\n",
    "stt_model = get_stt_model()\n",
    "tts_model = get_tts_model()\n",
    "\n",
    "async def echo(audio: tuple[int, np.ndarray]):\n",
    "    transcription = stt_model.stt(audio)\n",
    "    async for audio_chunk in tts_model.stream_tts(transcription):\n",
    "        yield audio_chunk\n",
    "\n",
    "stream = Stream(\n",
    "    handler=ReplyOnPause(echo),\n",
    "    modality=\"audio\",\n",
    "    mode=\"send-receive\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b25a76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5619c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_type application/json\n",
      "content_type application/json\n",
      "content_type application/json\n",
      "content_type application/json\n",
      "content_type application/json\n",
      "content_type application/json\n",
      "content_type application/json\n",
      "content_type application/json\n",
      "content_type application/json\n",
      "content_type application/json\n",
      "content_type application/json\n",
      "content_type application/json\n"
     ]
    }
   ],
   "source": [
    "stream.ui.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba8fcd",
   "metadata": {},
   "source": [
    "### Example 5\n",
    "\n",
    "We are going to attach an Agent between STT and TTS but for now with any tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc315ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fastrtc import ReplyOnPause, Stream, get_stt_model, get_tts_model\n",
    "from langchain.agents import create_agent\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Your name is Sarah, a funny voice assistant who loves telling jokes. \n",
    "You are part of a phone conversation, so don't use emojis or asterisks\n",
    "during your responses.\"\"\"\n",
    "\n",
    "stt_model = get_stt_model()\n",
    "llm = ChatGroq(\n",
    "    model=settings.groq.model, \n",
    "    api_key=settings.groq.api_key,\n",
    "    base_url=settings.groq.base_url\n",
    ")\n",
    "tts_model = get_tts_model()\n",
    "\n",
    "simple_agent = create_agent(\n",
    "    llm, checkpointer=InMemorySaver(), system_prompt=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c70b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def simple_agent_handler(audio: tuple[int, np.ndarray]):\n",
    "    # Generate the transcription using Moonshine model\n",
    "    transcription = stt_model.stt(audio)\n",
    "\n",
    "    # Use the transcription as user input to our agent and wait for the response\n",
    "    response = simple_agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": transcription}]},\n",
    "        {\"configurable\": {\"thread_id\": \"test\"}}\n",
    "    )\n",
    "\n",
    "    # Stream the audio response using the Kokoro model\n",
    "    async for audio_chunk in tts_model.stream_tts(response[\"messages\"][-1].content):\n",
    "        yield audio_chunk\n",
    "\n",
    "stream = Stream(\n",
    "    handler=ReplyOnPause(simple_agent_handler),\n",
    "    modality=\"audio\",\n",
    "    mode=\"send-receive\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1373b3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream.ui.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b899b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7850ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
